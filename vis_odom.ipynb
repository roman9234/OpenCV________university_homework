{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T15:35:16.784039Z",
     "start_time": "2025-04-09T15:33:25.918323Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class VisualOdometry:\n",
    "    def __init__(self, focal_length, principal_point):\n",
    "        \"\"\"\n",
    "        Инициализация визуальной одометрии.\n",
    "        :param focal_length: Фокусное расстояние камеры.\n",
    "        :param principal_point: Главная точка камеры (оптический центр).\n",
    "        \"\"\"\n",
    "        self.focal = focal_length\n",
    "        self.pp = principal_point\n",
    "        self.prev_image = None\n",
    "        self.prev_keypoints = None\n",
    "        self.R = np.eye(3)  # Матрица вращения\n",
    "        self.t = np.zeros((3, 1))  # Вектор трансляции\n",
    "\n",
    "    def process_frame(self, curr_image):\n",
    "        if self.prev_image is None:\n",
    "            self.prev_image = curr_image\n",
    "            self.prev_keypoints = self.detect_keypoints(curr_image)\n",
    "            return self.t.flatten()\n",
    "\n",
    "        # Найти соответствия между предыдущими и текущими ключевыми точками.\n",
    "        curr_keypoints, matches = self.track_keypoints(self.prev_image, curr_image, self.prev_keypoints)\n",
    "\n",
    "        if len(curr_keypoints) < 5 or len(self.prev_keypoints) < 5:\n",
    "            self.prev_image = curr_image\n",
    "            self.prev_keypoints = self.detect_keypoints(curr_image)\n",
    "            # print(\"Недостаточно ключевых точек для вычисления движения.\")\n",
    "            return self.t.flatten()\n",
    "\n",
    "        # Вычислить относительное движение между изображениями.\n",
    "        try:\n",
    "            E, mask = cv2.findEssentialMat(curr_keypoints, self.prev_keypoints, focal=self.focal, pp=self.pp, method=cv2.RANSAC)\n",
    "            _, R, t, mask = cv2.recoverPose(E, curr_keypoints, self.prev_keypoints, focal=self.focal, pp=self.pp)\n",
    "        except Exception as e:\n",
    "            self.prev_image = curr_image\n",
    "            self.prev_keypoints = self.detect_keypoints(curr_image)\n",
    "            return self.t.flatten()\n",
    "\n",
    "\n",
    "\n",
    "        # Обновить глобальную матрицу вращения и трансляции.\n",
    "        self.t += self.R @ t\n",
    "        self.R = R @ self.R\n",
    "\n",
    "        self.prev_image = curr_image\n",
    "        self.prev_keypoints = curr_keypoints[mask.ravel() == 1]\n",
    "        self.prev_keypoints = self.detect_keypoints(curr_image)\n",
    "\n",
    "        return self.t.flatten()\n",
    "\n",
    "\n",
    "    def detect_keypoints(self, image):\n",
    "        \"\"\"\n",
    "        Обнаружение ключевых точек на изображении.\n",
    "        :param image: Входное изображение.\n",
    "        :return: Массив ключевых точек.\n",
    "        \"\"\"\n",
    "        orb = cv2.ORB_create()\n",
    "        keypoints = orb.detect(image, None)\n",
    "        keypoints = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
    "        return keypoints\n",
    "\n",
    "    def track_keypoints(self, prev_image, curr_image, prev_keypoints):\n",
    "        # Оптическое отслеживание ключевых точек\n",
    "        try:\n",
    "            curr_keypoints, status, err = cv2.calcOpticalFlowPyrLK(prev_image, curr_image, prev_keypoints, None)\n",
    "        except Exception as e:\n",
    "            return [], []\n",
    "        # print(curr_keypoints)\n",
    "        # print(status)\n",
    "        # print(err)\n",
    "\n",
    "        # Проверка на случай, если status равен None\n",
    "        if status is None or curr_keypoints is None:\n",
    "            print(\"Не удалось отследить ключевые точки.\")\n",
    "            return [], []\n",
    "\n",
    "        # Фильтрация успешных ключевых точек\n",
    "        status = status.ravel()\n",
    "        prev_keypoints = prev_keypoints[status == 1]\n",
    "        curr_keypoints = curr_keypoints[status == 1]\n",
    "\n",
    "        return curr_keypoints, prev_keypoints\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "# Параметры камеры (замените на свои значения)\n",
    "focal_length = 718.856  # Примерное значение фокусного расстояния\n",
    "principal_point = (320, 240)  # Предположим, что камера 640x480\n",
    "vo = VisualOdometry(focal_length=focal_length, principal_point=principal_point)\n",
    "\n",
    "size = 400\n",
    "mult = 5\n",
    "\n",
    "traj = np.zeros(shape=(size, size, 3), dtype=np.uint8)\n",
    "traj_2 = np.zeros(shape=(size, size, 3), dtype=np.uint8)\n",
    "traj_3 = np.zeros(shape=(size, size, 3), dtype=np.uint8)\n",
    "\n",
    "x_prev = 0\n",
    "y_prev = 0\n",
    "z_prev = 0\n",
    "threshold = 0.5\n",
    "\n",
    "calc_x = 0\n",
    "calc_y = 0\n",
    "calc_z = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Отображение текущего кадра\n",
    "    # cv2.imshow('frame', frame)\n",
    "\n",
    "    # Преобразование изображения в градации серого\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # try:\n",
    "        # Обработка текущего кадра\n",
    "    position = vo.process_frame(img)\n",
    "    x = position[0]\n",
    "    y = position[1]\n",
    "    z = position[2]\n",
    "\n",
    "    if abs(x - x_prev) >= threshold:\n",
    "        calc_x += x - x_prev\n",
    "    if  abs(y - y_prev) >= threshold:\n",
    "        calc_y += y - y_prev\n",
    "    if  abs(z - z_prev) >= threshold:\n",
    "        calc_z += z - z_prev\n",
    "\n",
    "    x_prev = x\n",
    "    y_prev = y\n",
    "    z_prev = z\n",
    "\n",
    "    # print(f\"Текущая позиция камеры: x={x:.2f}, y={y:.2f}, z={z:.2f}\")\n",
    "    # Обновляем траектории\n",
    "    traj = cv2.circle(traj, (int(calc_x * mult) + size//2, int(calc_z * mult) + size//2), 1, (0, 255, 0), 1)\n",
    "    traj_2 = cv2.circle(traj_2, (int(calc_x * mult) + size//2, int(calc_y * mult) + size//2), 1, (0, 255, 0), 1)\n",
    "    traj_3 = cv2.circle(traj_3, (int(calc_y * mult) + size//2, int(calc_z * mult) + size//2), 1, (0, 255, 0), 1)\n",
    "\n",
    "    # Добавляем текст на траекторию\n",
    "    cv2.putText(traj, 'Trajectory X-Z', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(traj_2, 'Trajectory X-Y', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(traj_3, 'Trajectory Y-Z', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Изменяем размер текущего кадра до размера траекторий\n",
    "    resized_frame = cv2.resize(frame, (size, size))\n",
    "\n",
    "    # Объединяем изображения в одну матрицу\n",
    "    top_row = np.hstack((resized_frame, traj))\n",
    "    bottom_row = np.hstack((traj_2, traj_3))\n",
    "    combined_image = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    # Отображаем объединенное изображение\n",
    "    cv2.imshow('Visual Odometry', combined_image)\n",
    "\n",
    "        # Нажмите 'q', чтобы выйти из цикла\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) == ord('c'):\n",
    "        traj = np.zeros(shape=(size, size, 3))\n",
    "        traj_2 = np.zeros(shape=(size, size, 3))\n",
    "        traj_3 = np.zeros(shape=(size, size, 3))\n",
    "        vo.t = np.zeros((3, 1))\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
